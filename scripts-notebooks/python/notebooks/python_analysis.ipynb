{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2c87fe-fe17-4923-b4b0-4808d2f4d40b",
   "metadata": {},
   "source": [
    "# My ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2da39bf-5098-4cd3-accc-3ab6fdb96278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from sqlalchemy.exc import SQLAlchemyError, IntegrityError\n",
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4ed69b-e130-4053-93f9-6897144a1b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tables_in_supply_chain_db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inventory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>price_history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>suppliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>warehouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tables_in_supply_chain_db\n",
       "0                 inventory\n",
       "1                    orders\n",
       "2             price_history\n",
       "3                  products\n",
       "4                     sales\n",
       "5                 suppliers\n",
       "6                warehouses"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQLAlchemy connection string (inside Docker network)\n",
    "DB_USER = \"analytics_user\"\n",
    "DB_PASS = \"analyticspass123\"\n",
    "DB_HOST = \"mysql\"          # service name from docker-compose\n",
    "DB_PORT = \"3306\"\n",
    "DB_NAME = \"supply_chain_db\"\n",
    "\n",
    "connection_string = f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Quick test: list tables\n",
    "with engine.connect() as conn:\n",
    "    tables = pd.read_sql(\"SHOW TABLES;\", conn)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7b6cab-9fa7-441f-8415-9c925bb0443b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ETLConfig:\n",
    "    \"\"\"Configuration for ETL pipeline\"\"\"\n",
    "    db_host: str = \"mysql\"\n",
    "    db_port: int = 3306\n",
    "    db_user: str = \"analytics_user\"\n",
    "    db_password: str = \"analyticspass123\"\n",
    "    db_name: str = \"supply_chain_db\"\n",
    "    batch_size: int = 1000\n",
    "    max_retries: int = 3\n",
    "    retry_delay: int = 5\n",
    "    null_threshold: float = 0.05\n",
    "    duplicate_threshold: float = 0.01\n",
    "    log_level: str = \"INFO\"\n",
    "    log_file: str = \"etl_pipeline.log\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataQualityReport:\n",
    "    \"\"\"Data quality validation results\"\"\"\n",
    "    table_name: str\n",
    "    total_rows: int\n",
    "    null_count: Dict[str, int] = field(default_factory=dict)\n",
    "    duplicate_count: int = 0\n",
    "    missing_foreign_keys: Dict[str, int] = field(default_factory=dict)\n",
    "    validation_passed: bool = True\n",
    "    issues: List[str] = field(default_factory=list)\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    \n",
    "    def add_issue(self, issue: str):\n",
    "        self.issues.append(issue)\n",
    "        self.validation_passed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9215faea-bd58-4d01-8274-db840af7dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(config: ETLConfig) -> logging.Logger:\n",
    "    \"\"\"Configure logging with file and console handlers\"\"\"\n",
    "    logger = logging.getLogger('ETL_Pipeline')\n",
    "    logger.setLevel(getattr(logging, config.log_level))\n",
    "    logger.handlers = []\n",
    "    \n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    console_format = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    console_handler.setFormatter(console_format)\n",
    "    \n",
    "    file_handler = logging.FileHandler(config.log_file)\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    file_format = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    "    )\n",
    "    file_handler.setFormatter(file_format)\n",
    "    \n",
    "    logger.addHandler(console_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6bb386-ef18-4cf4-a175-c53b55ac0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseConnection:\n",
    "    \"\"\"Context manager for database connections with error handling\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ETLConfig, logger: logging.Logger):\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "        self.engine = None\n",
    "        self.connection = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        try:\n",
    "            connection_string = (\n",
    "                f\"mysql+pymysql://{self.config.db_user}:{self.config.db_password}\"\n",
    "                f\"@{self.config.db_host}:{self.config.db_port}/{self.config.db_name}\"\n",
    "            )\n",
    "            self.engine = create_engine(\n",
    "                connection_string,\n",
    "                pool_pre_ping=True,\n",
    "                pool_recycle=3600,\n",
    "                echo=False\n",
    "            )\n",
    "            self.connection = self.engine.connect()\n",
    "            self.logger.info(f\"✓ Connected to database: {self.config.db_name}\")\n",
    "            return self\n",
    "        except SQLAlchemyError as e:\n",
    "            self.logger.error(f\"✗ Database connection failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "            self.logger.info(\"✓ Database connection closed\")\n",
    "        if exc_type:\n",
    "            self.logger.error(f\"✗ Error during database operation: {exc_val}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d2896f-36a1-4dae-9567-881520e72d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExtractor:\n",
    "    \"\"\"Extract data from various sources\"\"\"\n",
    "    \n",
    "    def __init__(self, connection: DatabaseConnection, logger: logging.Logger):\n",
    "        self.connection = connection\n",
    "        self.logger = logger\n",
    "    \n",
    "    def extract_table(self, table_name: str, \n",
    "                     date_column: Optional[str] = None,\n",
    "                     start_date: Optional[datetime] = None,\n",
    "                     end_date: Optional[datetime] = None) -> pd.DataFrame:\n",
    "        try:\n",
    "            self.logger.info(f\"Extracting data from table: {table_name}\")\n",
    "            \n",
    "            query = f\"SELECT * FROM {table_name}\"\n",
    "            \n",
    "            if date_column and start_date and end_date:\n",
    "                query += f\" WHERE {date_column} BETWEEN :start_date AND :end_date\"\n",
    "                params = {'start_date': start_date, 'end_date': end_date}\n",
    "                df = pd.read_sql_query(text(query), self.connection.connection, params=params)\n",
    "            else:\n",
    "                df = pd.read_sql_query(query, self.connection.connection)\n",
    "            \n",
    "            self.logger.info(f\"✓ Extracted {len(df):,} rows from {table_name}\")\n",
    "            return df\n",
    "        except SQLAlchemyError as e:\n",
    "            self.logger.error(f\"✗ Failed to extract from {table_name}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def extract_with_joins(self, query: str, params: Optional[Dict] = None) -> pd.DataFrame:\n",
    "        try:\n",
    "            self.logger.info(\"Executing custom extraction query\")\n",
    "            if params:\n",
    "                df = pd.read_sql_query(text(query), self.connection.connection, params=params)\n",
    "            else:\n",
    "                df = pd.read_sql_query(query, self.connection.connection)\n",
    "            self.logger.info(f\"✓ Extracted {len(df):,} rows from custom query\")\n",
    "            return df\n",
    "        except SQLAlchemyError as e:\n",
    "            self.logger.error(f\"✗ Custom query failed: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2850cbc1-5b34-4f97-ae1b-c9c2c8283c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformer:\n",
    "    \"\"\"Transform and clean extracted data\"\"\"\n",
    "    \n",
    "    def __init__(self, logger: logging.Logger):\n",
    "        self.logger = logger\n",
    "    \n",
    "    def clean_nulls(self, df: pd.DataFrame, strategy: str = 'drop') -> pd.DataFrame:\n",
    "        null_count = df.isnull().sum().sum()\n",
    "        self.logger.info(f\"Handling {null_count} null values using strategy: {strategy}\")\n",
    "        \n",
    "        if strategy == 'drop':\n",
    "            return df.dropna()\n",
    "        elif strategy == 'fill_mean':\n",
    "            return df.fillna(df.mean(numeric_only=True))\n",
    "        elif strategy == 'fill_median':\n",
    "            return df.fillna(df.median(numeric_only=True))\n",
    "        elif strategy == 'fill_forward':\n",
    "            return df.fillna(method='ffill')\n",
    "        else:\n",
    "            self.logger.warning(f\"Unknown strategy '{strategy}', returning original DataFrame\")\n",
    "            return df\n",
    "    \n",
    "    def remove_duplicates(self, df: pd.DataFrame, \n",
    "                         subset: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "        initial_rows = len(df)\n",
    "        df_clean = df.drop_duplicates(subset=subset, keep='first')\n",
    "        removed = initial_rows - len(df_clean)\n",
    "        \n",
    "        if removed > 0:\n",
    "            self.logger.warning(f\"Removed {removed} duplicate rows\")\n",
    "        else:\n",
    "            self.logger.info(\"✓ No duplicates found\")\n",
    "        \n",
    "        return df_clean\n",
    "    \n",
    "    def standardize_dates(self, df: pd.DataFrame, \n",
    "                         date_columns: List[str],\n",
    "                         date_format: str = '%Y-%m-%d') -> pd.DataFrame:\n",
    "        for col in date_columns:\n",
    "            if col in df.columns:\n",
    "                try:\n",
    "                    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "                    self.logger.info(f\"✓ Standardized date column: {col}\")\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"✗ Failed to standardize {col}: {str(e)}\")\n",
    "        return df\n",
    "    \n",
    "    def add_derived_columns(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        self.logger.info(f\"Adding derived columns for {table_name}\")\n",
    "        \n",
    "        if table_name == 'inventory':\n",
    "            if 'quantity_on_hand' in df.columns and 'quantity_reserved' in df.columns:\n",
    "                df['quantity_available'] = df['quantity_on_hand'] - df['quantity_reserved']\n",
    "                self.logger.info(\"✓ Added 'quantity_available' column\")\n",
    "        \n",
    "        elif table_name == 'orders':\n",
    "            if 'expected_delivery_date' in df.columns and 'actual_delivery_date' in df.columns:\n",
    "                df['delivery_delay_days'] = (\n",
    "                    pd.to_datetime(df['actual_delivery_date']) - \n",
    "                    pd.to_datetime(df['expected_delivery_date'])\n",
    "                ).dt.days\n",
    "                df['is_late'] = df['delivery_delay_days'] > 0\n",
    "                self.logger.info(\"✓ Added delivery metrics columns\")\n",
    "        \n",
    "        elif table_name == 'sales':\n",
    "            if 'revenue' in df.columns and 'quantity_sold' in df.columns:\n",
    "                df['unit_price'] = df['revenue'] / df['quantity_sold']\n",
    "                self.logger.info(\"✓ Added 'unit_price' column\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def apply_business_rules(self, df: pd.DataFrame, table_name: str) -> pd.DataFrame:\n",
    "        self.logger.info(f\"Applying business rules for {table_name}\")\n",
    "        initial_rows = len(df)\n",
    "        \n",
    "        if table_name == 'products':\n",
    "            df = df[df['unit_cost'] > 0]\n",
    "            df = df[df['reorder_level'] >= 0]\n",
    "        elif table_name == 'inventory':\n",
    "            df = df[df['quantity_on_hand'] >= 0]\n",
    "            df = df[df['quantity_reserved'] >= 0]\n",
    "        elif table_name == 'orders':\n",
    "            df = df[df['order_quantity'] > 0]\n",
    "            df = df[df['order_cost'] >= 0]\n",
    "        elif table_name == 'sales':\n",
    "            df = df[df['quantity_sold'] > 0]\n",
    "            df = df[df['revenue'] >= 0]\n",
    "        \n",
    "        removed = initial_rows - len(df)\n",
    "        if removed > 0:\n",
    "            self.logger.warning(f\"Removed {removed} rows violating business rules\")\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7cd44b0-0f56-4210-bb22-875de64b5341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ETL PIPELINE INITIALIZED\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Connected to database: supply_chain_db\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - \n",
      "======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Processing table: suppliers\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Extracting data from table: suppliers\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Extracted 30 rows from suppliers\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ No duplicates found\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Standardized date column: created_date\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Adding derived columns for suppliers\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Applying business rules for suppliers\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - === Validating data quality for: suppliers ===\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Data quality validation PASSED for suppliers\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Successfully processed suppliers\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - \n",
      "======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Processing table: products\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Extracting data from table: products\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Extracted 46 rows from products\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ No duplicates found\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Adding derived columns for products\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Applying business rules for products\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - === Validating data quality for: products ===\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Data quality validation PASSED for products\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Successfully processed products\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - \n",
      "======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Processing table: warehouses\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Extracting data from table: warehouses\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Extracted 18 rows from warehouses\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ No duplicates found\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Adding derived columns for warehouses\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Applying business rules for warehouses\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - === Validating data quality for: warehouses ===\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Data quality validation PASSED for warehouses\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Successfully processed warehouses\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - \n",
      "======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Processing table: inventory\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Extracting data from table: inventory\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Extracted 263 rows from inventory\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ No duplicates found\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Standardized date column: snapshot_date\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Adding derived columns for inventory\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Added 'quantity_available' column\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Applying business rules for inventory\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - === Validating data quality for: inventory ===\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Data quality validation PASSED for inventory\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Successfully processed inventory\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - \n",
      "======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Processing table: orders\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Extracting data from table: orders\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Extracted 67 rows from orders\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ No duplicates found\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Standardized date column: order_date\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Standardized date column: expected_delivery_date\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Standardized date column: actual_delivery_date\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Adding derived columns for orders\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Added delivery metrics columns\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Applying business rules for orders\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - === Validating data quality for: orders ===\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - WARNING - ⚠ High null count in 'actual_delivery_date': 31 (46.3%)\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - WARNING - ⚠ High null count in 'delivery_delay_days': 31 (46.3%)\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - ERROR - ✗ Data quality validation FAILED for orders\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - WARNING - ⚠ Quality validation failed for orders, skipping load\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - \n",
      "======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Processing table: sales\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Extracting data from table: sales\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Extracted 166 rows from sales\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ No duplicates found\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Standardized date column: sale_date\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Adding derived columns for sales\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Added 'unit_price' column\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Applying business rules for sales\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - === Validating data quality for: sales ===\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Data quality validation PASSED for sales\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Successfully processed sales\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - \n",
      "======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Processing table: price_history\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Extracting data from table: price_history\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Extracted 110 rows from price_history\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ No duplicates found\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Standardized date column: effective_date\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Adding derived columns for price_history\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - Applying business rules for price_history\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - === Validating data quality for: price_history ===\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Data quality validation PASSED for price_history\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Successfully processed price_history\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - \n",
      "======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ETL PIPELINE COMPLETED\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ======================================================================\n",
      "2026-02-01 16:45:02 - ETL_Pipeline - INFO - ✓ Database connection closed\n",
      "\n",
      "✗ Pipeline completed with errors\n",
      "\n",
      "Processed: 6 tables\n",
      "Failed: 1 tables\n"
     ]
    }
   ],
   "source": [
    "class DataQualityValidator:\n",
    "    \"\"\"Comprehensive data quality checks\"\"\"\n",
    "    \n",
    "    def __init__(self, connection: DatabaseConnection, \n",
    "                 config: ETLConfig, logger: logging.Logger):\n",
    "        self.connection = connection\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "    \n",
    "    def validate_table(self, df: pd.DataFrame, \n",
    "                      table_name: str,\n",
    "                      required_columns: Optional[List[str]] = None) -> DataQualityReport:\n",
    "        self.logger.info(f\"=== Validating data quality for: {table_name} ===\")\n",
    "        report = DataQualityReport(table_name=table_name, total_rows=len(df))\n",
    "        \n",
    "        if required_columns:\n",
    "            missing_cols = set(required_columns) - set(df.columns)\n",
    "            if missing_cols:\n",
    "                report.add_issue(f\"Missing required columns: {missing_cols}\")\n",
    "                self.logger.error(f\"✗ Missing columns: {missing_cols}\")\n",
    "        \n",
    "        null_counts = df.isnull().sum()\n",
    "        for col, count in null_counts.items():\n",
    "            if count > 0:\n",
    "                null_pct = count / len(df)\n",
    "                report.null_count[col] = count\n",
    "                \n",
    "                if null_pct > self.config.null_threshold:\n",
    "                    report.add_issue(\n",
    "                        f\"Column '{col}' has {null_pct:.1%} nulls (threshold: {self.config.null_threshold:.1%})\"\n",
    "                    )\n",
    "                    self.logger.warning(f\"⚠ High null count in '{col}': {count} ({null_pct:.1%})\")\n",
    "        \n",
    "        if len(df) > 0:\n",
    "            duplicate_count = df.duplicated().sum()\n",
    "            report.duplicate_count = duplicate_count\n",
    "            \n",
    "            if duplicate_count > 0:\n",
    "                dup_pct = duplicate_count / len(df)\n",
    "                if dup_pct > self.config.duplicate_threshold:\n",
    "                    report.add_issue(f\"Found {duplicate_count} duplicates ({dup_pct:.1%})\")\n",
    "                    self.logger.warning(f\"⚠ Duplicates found: {duplicate_count}\")\n",
    "        \n",
    "        fk_issues = self._validate_foreign_keys(df, table_name)\n",
    "        if fk_issues:\n",
    "            report.missing_foreign_keys = fk_issues\n",
    "            for fk, count in fk_issues.items():\n",
    "                report.add_issue(f\"Missing foreign key references in '{fk}': {count} rows\")\n",
    "                self.logger.error(f\"✗ Foreign key issue in '{fk}': {count} orphaned rows\")\n",
    "        \n",
    "        if report.validation_passed:\n",
    "            self.logger.info(f\"✓ Data quality validation PASSED for {table_name}\")\n",
    "        else:\n",
    "            self.logger.error(f\"✗ Data quality validation FAILED for {table_name}\")\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _validate_foreign_keys(self, df: pd.DataFrame, table_name: str) -> Dict[str, int]:\n",
    "        issues = {}\n",
    "        fk_mapping = {\n",
    "            'products': {'supplier_id': 'suppliers'},\n",
    "            'inventory': {'product_id': 'products', 'warehouse_id': 'warehouses'},\n",
    "            'orders': {'supplier_id': 'suppliers'},\n",
    "            'sales': {'product_id': 'products', 'warehouse_id': 'warehouses'},\n",
    "            'price_history': {'product_id': 'products', 'supplier_id': 'suppliers'}\n",
    "        }\n",
    "        \n",
    "        if table_name not in fk_mapping:\n",
    "            return issues\n",
    "        \n",
    "        for fk_col, parent_table in fk_mapping[table_name].items():\n",
    "            if fk_col not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                parent_ids = pd.read_sql_query(\n",
    "                    f\"SELECT {fk_col.replace('_id', '')}_id FROM {parent_table}\",\n",
    "                    self.connection.connection\n",
    "                )\n",
    "                valid_ids = set(parent_ids.iloc[:, 0])\n",
    "                orphaned = ~df[fk_col].isin(valid_ids)\n",
    "                orphaned_count = orphaned.sum()\n",
    "                \n",
    "                if orphaned_count > 0:\n",
    "                    issues[fk_col] = orphaned_count\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Could not validate FK {fk_col}: {str(e)}\")\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    def generate_quality_summary(self, reports: List[DataQualityReport]) -> pd.DataFrame:\n",
    "        summary_data = []\n",
    "        for report in reports:\n",
    "            summary_data.append({\n",
    "                'table_name': report.table_name,\n",
    "                'total_rows': report.total_rows,\n",
    "                'null_columns': len(report.null_count),\n",
    "                'total_nulls': sum(report.null_count.values()),\n",
    "                'duplicates': report.duplicate_count,\n",
    "                'fk_issues': len(report.missing_foreign_keys),\n",
    "                'validation_passed': report.validation_passed,\n",
    "                'issue_count': len(report.issues),\n",
    "                'timestamp': report.timestamp\n",
    "            })\n",
    "        return pd.DataFrame(summary_data)\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Load transformed data into database\"\"\"\n",
    "    \n",
    "    def __init__(self, connection: DatabaseConnection, \n",
    "                 config: ETLConfig, logger: logging.Logger):\n",
    "        self.connection = connection\n",
    "        self.config = config\n",
    "        self.logger = logger\n",
    "    \n",
    "    def load_data(self, df: pd.DataFrame, table_name: str,\n",
    "                  if_exists: str = 'append',\n",
    "                  create_backup: bool = True) -> Tuple[int, int]:\n",
    "        self.logger.info(f\"Loading {len(df)} rows into table: {table_name}\")\n",
    "        \n",
    "        rows_loaded = 0\n",
    "        rows_failed = 0\n",
    "        \n",
    "        try:\n",
    "            if create_backup and if_exists == 'replace':\n",
    "                self._create_backup(table_name)\n",
    "            \n",
    "            for i in range(0, len(df), self.config.batch_size):\n",
    "                batch = df.iloc[i:i + self.config.batch_size]\n",
    "                \n",
    "                try:\n",
    "                    batch.to_sql(\n",
    "                        name=table_name,\n",
    "                        con=self.connection.engine,\n",
    "                        if_exists=if_exists if i == 0 else 'append',\n",
    "                        index=False,\n",
    "                        method='multi'\n",
    "                    )\n",
    "                    rows_loaded += len(batch)\n",
    "                except IntegrityError as e:\n",
    "                    self.logger.error(f\"Integrity error in batch: {str(e)}\")\n",
    "                    rows_failed += len(batch)\n",
    "                except SQLAlchemyError as e:\n",
    "                    self.logger.error(f\"Database error in batch: {str(e)}\")\n",
    "                    rows_failed += len(batch)\n",
    "            \n",
    "            self.logger.info(f\"✓ Load completed: {rows_loaded} rows loaded, {rows_failed} rows failed\")\n",
    "            return rows_loaded, rows_failed\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"✗ Load failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _create_backup(self, table_name: str):\n",
    "        backup_name = f\"{table_name}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        try:\n",
    "            with self.connection.connection.begin():\n",
    "                self.connection.connection.execute(\n",
    "                    text(f\"CREATE TABLE {backup_name} AS SELECT * FROM {table_name}\")\n",
    "                )\n",
    "            self.logger.info(f\"✓ Created backup table: {backup_name}\")\n",
    "        except SQLAlchemyError as e:\n",
    "            self.logger.warning(f\"Could not create backup: {str(e)}\")\n",
    "\n",
    "\n",
    "class ETLPipeline:\n",
    "    \"\"\"Main ETL pipeline orchestrator\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Optional[ETLConfig] = None):\n",
    "        self.config = config or ETLConfig()\n",
    "        self.logger = setup_logging(self.config)\n",
    "        self.quality_reports = []\n",
    "        \n",
    "        self.logger.info(\"=\" * 70)\n",
    "        self.logger.info(\"ETL PIPELINE INITIALIZED\")\n",
    "        self.logger.info(\"=\" * 70)\n",
    "    \n",
    "    def run_full_pipeline(self, tables: List[str]) -> Dict[str, any]:\n",
    "        results = {\n",
    "            'success': False,\n",
    "            'tables_processed': [],\n",
    "            'tables_failed': [],\n",
    "            'quality_reports': [],\n",
    "            'summary': {}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            with DatabaseConnection(self.config, self.logger) as db:\n",
    "                extractor = DataExtractor(db, self.logger)\n",
    "                transformer = DataTransformer(self.logger)\n",
    "                validator = DataQualityValidator(db, self.config, self.logger)\n",
    "                loader = DataLoader(db, self.config, self.logger)\n",
    "                \n",
    "                for table in tables:\n",
    "                    try:\n",
    "                        self.logger.info(f\"\\n{'='*70}\")\n",
    "                        self.logger.info(f\"Processing table: {table}\")\n",
    "                        self.logger.info(f\"{'='*70}\")\n",
    "                        \n",
    "                        df = extractor.extract_table(table)\n",
    "                        # df = transformer.clean_nulls(df, strategy='drop')\n",
    "                        df = transformer.remove_duplicates(df)\n",
    "                        df = transformer.standardize_dates(\n",
    "                            df, \n",
    "                            date_columns=[col for col in df.columns if 'date' in col.lower()]\n",
    "                        )\n",
    "                        df = transformer.add_derived_columns(df, table)\n",
    "                        df = transformer.apply_business_rules(df, table)\n",
    "                        \n",
    "                        report = validator.validate_table(df, table)\n",
    "                        self.quality_reports.append(report)\n",
    "                        \n",
    "                        if not report.validation_passed:\n",
    "                            self.logger.warning(f\"⚠ Quality validation failed for {table}, skipping load\")\n",
    "                            results['tables_failed'].append(table)\n",
    "                            continue\n",
    "                        \n",
    "                        results['tables_processed'].append(table)\n",
    "                        self.logger.info(f\"✓ Successfully processed {table}\")\n",
    "                    except Exception as e:\n",
    "                        self.logger.error(f\"✗ Failed to process {table}: {str(e)}\")\n",
    "                        results['tables_failed'].append(table)\n",
    "                \n",
    "                results['quality_reports'] = self.quality_reports\n",
    "                results['summary'] = validator.generate_quality_summary(self.quality_reports)\n",
    "                results['success'] = len(results['tables_failed']) == 0\n",
    "                \n",
    "                self.logger.info(\"\\n\" + \"=\"*70)\n",
    "                self.logger.info(\"ETL PIPELINE COMPLETED\")\n",
    "                self.logger.info(\"=\"*70)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"✗ Pipeline failed: {str(e)}\")\n",
    "            results['success'] = False\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = ETLConfig()\n",
    "    pipeline = ETLPipeline(config)\n",
    "    tables_to_process = ['suppliers', 'products', 'warehouses', 'inventory', 'orders', 'sales', 'price_history']\n",
    "    results = pipeline.run_full_pipeline(tables_to_process)\n",
    "    \n",
    "    if results['success']:\n",
    "        print(\"\\n✓ Pipeline completed successfully!\")\n",
    "    else:\n",
    "        print(\"\\n✗ Pipeline completed with errors\")\n",
    "    \n",
    "    print(f\"\\nProcessed: {len(results['tables_processed'])} tables\")\n",
    "    print(f\"Failed: {len(results['tables_failed'])} tables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68780c1a-2b58-449a-b54d-b36dda63003d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Framework - Ready for integration with ETL Pipeline\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ValidationRule:\n",
    "    \"\"\"Individual validation rule definition\"\"\"\n",
    "    rule_name: str\n",
    "    rule_type: str\n",
    "    column: Optional[str] = None\n",
    "    threshold: Optional[float] = None\n",
    "    condition: Optional[Callable] = None\n",
    "    severity: str = 'WARNING'\n",
    "    description: str = \"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ValidationResult:\n",
    "    \"\"\"Result of a validation rule execution\"\"\"\n",
    "    rule_name: str\n",
    "    passed: bool\n",
    "    severity: str\n",
    "    message: str\n",
    "    affected_rows: int = 0\n",
    "    affected_percentage: float = 0.0\n",
    "    details: Dict = field(default_factory=dict)\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "\n",
    "class DataQualityRulesEngine:\n",
    "    \"\"\"Engine to define and execute data quality rules\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rules: Dict[str, List[ValidationRule]] = {}\n",
    "        self.results: List[ValidationResult] = []\n",
    "    \n",
    "    def add_rule(self, table_name: str, rule: ValidationRule):\n",
    "        \"\"\"Add validation rule for a specific table\"\"\"\n",
    "        if table_name not in self.rules:\n",
    "            self.rules[table_name] = []\n",
    "        self.rules[table_name].append(rule)\n",
    "    \n",
    "    def define_standard_rules(self):\n",
    "        \"\"\"Define standard data quality rules for all tables\"\"\"\n",
    "        \n",
    "        # SUPPLIERS\n",
    "        self.add_rule('suppliers', ValidationRule(\n",
    "            rule_name='supplier_id_unique',\n",
    "            rule_type='uniqueness',\n",
    "            column='supplier_id',\n",
    "            severity='CRITICAL',\n",
    "            description='Supplier ID must be unique'\n",
    "        ))\n",
    "        \n",
    "        self.add_rule('suppliers', ValidationRule(\n",
    "            rule_name='reliability_score_range',\n",
    "            rule_type='validity',\n",
    "            column='reliability_score',\n",
    "            condition=lambda df: (df['reliability_score'] >= 0) & (df['reliability_score'] <= 100),\n",
    "            severity='CRITICAL',\n",
    "            description='Reliability score must be between 0 and 100'\n",
    "        ))\n",
    "        \n",
    "        # PRODUCTS\n",
    "        self.add_rule('products', ValidationRule(\n",
    "            rule_name='product_id_unique',\n",
    "            rule_type='uniqueness',\n",
    "            column='product_id',\n",
    "            severity='CRITICAL',\n",
    "            description='Product ID must be unique'\n",
    "        ))\n",
    "        \n",
    "        self.add_rule('products', ValidationRule(\n",
    "            rule_name='unit_cost_positive',\n",
    "            rule_type='validity',\n",
    "            column='unit_cost',\n",
    "            condition=lambda df: df['unit_cost'] > 0,\n",
    "            severity='CRITICAL',\n",
    "            description='Unit cost must be positive'\n",
    "        ))\n",
    "        \n",
    "        # INVENTORY\n",
    "        self.add_rule('inventory', ValidationRule(\n",
    "            rule_name='quantity_on_hand_valid',\n",
    "            rule_type='validity',\n",
    "            column='quantity_on_hand',\n",
    "            condition=lambda df: df['quantity_on_hand'] >= 0,\n",
    "            severity='CRITICAL',\n",
    "            description='Quantity on hand cannot be negative'\n",
    "        ))\n",
    "        \n",
    "        self.add_rule('inventory', ValidationRule(\n",
    "            rule_name='reserved_not_exceed_onhand',\n",
    "            rule_type='consistency',\n",
    "            column='quantity_reserved',\n",
    "            condition=lambda df: df['quantity_reserved'] <= df['quantity_on_hand'],\n",
    "            severity='CRITICAL',\n",
    "            description='Reserved quantity cannot exceed quantity on hand'\n",
    "        ))\n",
    "        \n",
    "        # ORDERS\n",
    "        self.add_rule('orders', ValidationRule(\n",
    "            rule_name='order_quantity_positive',\n",
    "            rule_type='validity',\n",
    "            column='order_quantity',\n",
    "            condition=lambda df: df['order_quantity'] > 0,\n",
    "            severity='CRITICAL',\n",
    "            description='Order quantity must be positive'\n",
    "        ))\n",
    "        \n",
    "        # SALES\n",
    "        self.add_rule('sales', ValidationRule(\n",
    "            rule_name='quantity_sold_positive',\n",
    "            rule_type='validity',\n",
    "            column='quantity_sold',\n",
    "            condition=lambda df: df['quantity_sold'] > 0,\n",
    "            severity='CRITICAL',\n",
    "            description='Quantity sold must be positive'\n",
    "        ))\n",
    "    \n",
    "    def execute_rules(self, df: pd.DataFrame, table_name: str) -> List[ValidationResult]:\n",
    "        \"\"\"Execute all rules for a given table\"\"\"\n",
    "        if table_name not in self.rules:\n",
    "            return []\n",
    "        \n",
    "        results = []\n",
    "        total_rows = len(df)\n",
    "        \n",
    "        for rule in self.rules[table_name]:\n",
    "            try:\n",
    "                if rule.rule_type == 'uniqueness':\n",
    "                    result = self._check_uniqueness(df, rule, total_rows)\n",
    "                elif rule.rule_type == 'completeness':\n",
    "                    result = self._check_completeness(df, rule, total_rows)\n",
    "                elif rule.rule_type in ['validity', 'consistency']:\n",
    "                    result = self._check_condition(df, rule, total_rows)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                results.append(ValidationResult(\n",
    "                    rule_name=rule.rule_name,\n",
    "                    passed=False,\n",
    "                    severity='CRITICAL',\n",
    "                    message=f\"Rule execution failed: {str(e)}\"\n",
    "                ))\n",
    "        \n",
    "        self.results.extend(results)\n",
    "        return results\n",
    "    \n",
    "    def _check_uniqueness(self, df: pd.DataFrame, rule: ValidationRule, \n",
    "                         total_rows: int) -> ValidationResult:\n",
    "        \"\"\"Check if column values are unique\"\"\"\n",
    "        duplicates = df[rule.column].duplicated().sum()\n",
    "        passed = duplicates == 0\n",
    "        \n",
    "        return ValidationResult(\n",
    "            rule_name=rule.rule_name,\n",
    "            passed=passed,\n",
    "            severity=rule.severity,\n",
    "            message=f\"{'✓ PASS' if passed else '✗ FAIL'}: {rule.description}\",\n",
    "            affected_rows=duplicates,\n",
    "            affected_percentage=(duplicates / total_rows * 100) if total_rows > 0 else 0,\n",
    "            details={'duplicate_count': int(duplicates)}\n",
    "        )\n",
    "    \n",
    "    def _check_completeness(self, df: pd.DataFrame, rule: ValidationRule,\n",
    "                           total_rows: int) -> ValidationResult:\n",
    "        \"\"\"Check for null/missing values\"\"\"\n",
    "        null_count = df[rule.column].isnull().sum()\n",
    "        null_pct = (null_count / total_rows * 100) if total_rows > 0 else 0\n",
    "        passed = null_pct <= (rule.threshold or 0.0)\n",
    "        \n",
    "        return ValidationResult(\n",
    "            rule_name=rule.rule_name,\n",
    "            passed=passed,\n",
    "            severity=rule.severity,\n",
    "            message=f\"{'✓ PASS' if passed else '✗ FAIL'}: {rule.description}\",\n",
    "            affected_rows=null_count,\n",
    "            affected_percentage=null_pct,\n",
    "            details={'null_count': int(null_count), 'null_percentage': null_pct}\n",
    "        )\n",
    "    \n",
    "    def _check_condition(self, df: pd.DataFrame, rule: ValidationRule,\n",
    "                        total_rows: int) -> ValidationResult:\n",
    "        \"\"\"Check custom condition\"\"\"\n",
    "        if rule.condition is None:\n",
    "            return ValidationResult(\n",
    "                rule_name=rule.rule_name,\n",
    "                passed=False,\n",
    "                severity='CRITICAL',\n",
    "                message=\"No condition defined for rule\"\n",
    "            )\n",
    "        \n",
    "        try:\n",
    "            valid = rule.condition(df)\n",
    "            invalid_count = (~valid).sum()\n",
    "            passed = invalid_count == 0\n",
    "            \n",
    "            return ValidationResult(\n",
    "                rule_name=rule.rule_name,\n",
    "                passed=passed,\n",
    "                severity=rule.severity,\n",
    "                message=f\"{'✓ PASS' if passed else '✗ FAIL'}: {rule.description}\",\n",
    "                affected_rows=invalid_count,\n",
    "                affected_percentage=(invalid_count / total_rows * 100) if total_rows > 0 else 0,\n",
    "                details={'invalid_count': int(invalid_count)}\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return ValidationResult(\n",
    "                rule_name=rule.rule_name,\n",
    "                passed=False,\n",
    "                severity='CRITICAL',\n",
    "                message=f\"Condition evaluation failed: {str(e)}\"\n",
    "            )\n",
    "    \n",
    "    def get_summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of all validation results\"\"\"\n",
    "        summary_data = []\n",
    "        \n",
    "        for result in self.results:\n",
    "            summary_data.append({\n",
    "                'rule_name': result.rule_name,\n",
    "                'status': '✓ PASS' if result.passed else '✗ FAIL',\n",
    "                'severity': result.severity,\n",
    "                'affected_rows': result.affected_rows,\n",
    "                'affected_percentage': f\"{result.affected_percentage:.2f}%\",\n",
    "                'timestamp': result.timestamp.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(summary_data)\n",
    "\n",
    "\n",
    "class DataProfiler:\n",
    "    \"\"\"Generate comprehensive data profiles\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def profile_numeric_column(series: pd.Series) -> Dict:\n",
    "        \"\"\"Profile a numeric column\"\"\"\n",
    "        return {\n",
    "            'count': int(series.count()),\n",
    "            'missing': int(series.isnull().sum()),\n",
    "            'mean': float(series.mean()),\n",
    "            'median': float(series.median()),\n",
    "            'std': float(series.std()),\n",
    "            'min': float(series.min()),\n",
    "            'max': float(series.max()),\n",
    "            'q25': float(series.quantile(0.25)),\n",
    "            'q75': float(series.quantile(0.75)),\n",
    "            'skewness': float(series.skew()),\n",
    "            'kurtosis': float(series.kurtosis())\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def profile_categorical_column(series: pd.Series) -> Dict:\n",
    "        \"\"\"Profile a categorical column\"\"\"\n",
    "        value_counts = series.value_counts()\n",
    "        \n",
    "        return {\n",
    "            'count': int(series.count()),\n",
    "            'missing': int(series.isnull().sum()),\n",
    "            'unique': int(series.nunique()),\n",
    "            'top_value': str(value_counts.index) if len(value_counts) > 0 else None,\n",
    "            'top_frequency': int(value_counts.iloc) if len(value_counts) > 0 else 0,\n",
    "            'value_distribution': value_counts.head(10).to_dict()\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def profile_date_column(series: pd.Series) -> Dict:\n",
    "        \"\"\"Profile a date column\"\"\"\n",
    "        series_dt = pd.to_datetime(series, errors='coerce')\n",
    "        \n",
    "        return {\n",
    "            'count': int(series_dt.count()),\n",
    "            'missing': int(series_dt.isnull().sum()),\n",
    "            'min_date': str(series_dt.min()),\n",
    "            'max_date': str(series_dt.max()),\n",
    "            'date_range_days': int((series_dt.max() - series_dt.min()).days) if series_dt.count() > 0 else 0\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def profile_dataframe(df: pd.DataFrame, table_name: str) -> Dict:\n",
    "        \"\"\"Generate comprehensive profile for entire DataFrame\"\"\"\n",
    "        profile = {\n",
    "            'table_name': table_name,\n",
    "            'row_count': len(df),\n",
    "            'column_count': len(df.columns),\n",
    "            'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024**2,\n",
    "            'duplicate_rows': int(df.duplicated().sum()),\n",
    "            'columns': {}\n",
    "        }\n",
    "        \n",
    "        for col in df.columns:\n",
    "            col_profile = {\n",
    "                'dtype': str(df[col].dtype),\n",
    "                'null_count': int(df[col].isnull().sum()),\n",
    "                'null_percentage': float(df[col].isnull().sum() / len(df) * 100)\n",
    "            }\n",
    "            \n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                col_profile['stats'] = DataProfiler.profile_numeric_column(df[col])\n",
    "            elif pd.api.types.is_datetime64_any_dtype(df[col]) or 'date' in col.lower():\n",
    "                col_profile['stats'] = DataProfiler.profile_date_column(df[col])\n",
    "            else:\n",
    "                col_profile['stats'] = DataProfiler.profile_categorical_column(df[col])\n",
    "            \n",
    "            profile['columns'][col] = col_profile\n",
    "        \n",
    "        return profile\n",
    "\n",
    "\n",
    "class AnomalyDetector:\n",
    "    \"\"\"Detect anomalies in data using statistical methods\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_outliers_iqr(series: pd.Series, multiplier: float = 1.5) -> pd.Series:\n",
    "        \"\"\"Detect outliers using IQR method\"\"\"\n",
    "        Q1 = series.quantile(0.25)\n",
    "        Q3 = series.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - multiplier * IQR\n",
    "        upper_bound = Q3 + multiplier * IQR\n",
    "        \n",
    "        return (series < lower_bound) | (series > upper_bound)\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_outliers_zscore(series: pd.Series, threshold: float = 3.0) -> pd.Series:\n",
    "        \"\"\"Detect outliers using Z-score method\"\"\"\n",
    "        z_scores = np.abs(stats.zscore(series.dropna()))\n",
    "        return pd.Series([z > threshold for z in z_scores], index=series.dropna().index)\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_outliers_isolation_forest(df: pd.DataFrame, \n",
    "                                        columns: List[str],\n",
    "                                        contamination: float = 0.1) -> np.ndarray:\n",
    "        \"\"\"Detect multivariate outliers using Isolation Forest\"\"\"\n",
    "        X = df[columns].select_dtypes(include=[np.number]).dropna()\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            return np.array([])\n",
    "        \n",
    "        iso_forest = IsolationForest(\n",
    "            contamination=contamination,\n",
    "            random_state=42,\n",
    "            n_estimators=100\n",
    "        )\n",
    "        \n",
    "        predictions = iso_forest.fit_predict(X)\n",
    "        return predictions\n",
    "    \n",
    "    @staticmethod\n",
    "    def analyze_table_anomalies(df: pd.DataFrame, table_name: str) -> Dict:\n",
    "        \"\"\"Comprehensive anomaly analysis for a table\"\"\"\n",
    "        results = {\n",
    "            'table_name': table_name,\n",
    "            'total_rows': len(df),\n",
    "            'columns_analyzed': [],\n",
    "            'outliers_detected': {}\n",
    "        }\n",
    "        \n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if df[col].nunique() > 10:\n",
    "                outliers_iqr = AnomalyDetector.detect_outliers_iqr(df[col])\n",
    "                outlier_count = outliers_iqr.sum()\n",
    "                \n",
    "                results['columns_analyzed'].append(col)\n",
    "                results['outliers_detected'][col] = {\n",
    "                    'method': 'IQR',\n",
    "                    'count': int(outlier_count),\n",
    "                    'percentage': float(outlier_count / len(df) * 100),\n",
    "                    'outlier_values': df[col][outliers_iqr].tolist()[:10]\n",
    "                }\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "class DataQualityReportGenerator:\n",
    "    \"\"\"Generate comprehensive data quality reports\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_html_report(validation_results: List[ValidationResult],\n",
    "                            profiles: Dict[str, Dict],\n",
    "                            anomalies: Dict[str, Dict],\n",
    "                            output_path: str = 'data_quality_report.html'):\n",
    "        \"\"\"Generate HTML data quality report\"\"\"\n",
    "        \n",
    "        passed = sum(1 for r in validation_results if r.passed)\n",
    "        failed = sum(1 for r in validation_results if not r.passed)\n",
    "        \n",
    "        validation_rows = \"\"\n",
    "        for result in validation_results:\n",
    "            status_class = 'pass' if result.passed else 'fail'\n",
    "            validation_rows += f\"\"\"\n",
    "            <tr>\n",
    "                <td><span class=\"{status_class}\">{'✓' if result.passed else '✗'}</span> {result.rule_name}</td>\n",
    "                <td class=\"{result.severity.lower()}\">{result.severity}</td>\n",
    "                <td>{result.message}</td>\n",
    "                <td>{result.affected_rows}</td>\n",
    "                <td>{result.affected_percentage:.2f}%</td>\n",
    "            </tr>\n",
    "            \"\"\"\n",
    "        \n",
    "        html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Data Quality Report</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}\n",
    "        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; }}\n",
    "        h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; }}\n",
    "        .summary {{ display: flex; justify-content: space-around; margin: 20px 0; }}\n",
    "        .metric {{ text-align: center; padding: 20px; background: #ecf0f1; border-radius: 8px; }}\n",
    "        .metric-value {{ font-size: 2em; font-weight: bold; color: #2c3e50; }}\n",
    "        .pass {{ color: #27ae60; }}\n",
    "        .fail {{ color: #e74c3c; }}\n",
    "        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}\n",
    "        th {{ background: #34495e; color: white; padding: 12px; text-align: left; }}\n",
    "        td {{ padding: 10px; border-bottom: 1px solid #ecf0f1; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>🔍 Data Quality Report</h1>\n",
    "        <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "        \n",
    "        <div class=\"summary\">\n",
    "            <div class=\"metric\">\n",
    "                <div class=\"metric-value pass\">{passed}</div>\n",
    "                <div>Rules Passed</div>\n",
    "            </div>\n",
    "            <div class=\"metric\">\n",
    "                <div class=\"metric-value fail\">{failed}</div>\n",
    "                <div>Rules Failed</div>\n",
    "            </div>\n",
    "            <div class=\"metric\">\n",
    "                <div class=\"metric-value\">{len(profiles)}</div>\n",
    "                <div>Tables Analyzed</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <h2>Validation Results</h2>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <th>Rule</th>\n",
    "                <th>Severity</th>\n",
    "                <th>Message</th>\n",
    "                <th>Affected Rows</th>\n",
    "                <th>Percentage</th>\n",
    "            </tr>\n",
    "            {validation_rows}\n",
    "        </table>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "        \"\"\"\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(html_content)\n",
    "        \n",
    "        return output_path\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Data Quality Framework - Ready for integration with ETL Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf079e2-19e9-41c2-9e03-b1dbd220cd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e8033-5145-44f9-9ae7-1ad7f4e1484a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03da42a-e814-471f-8f20-db74b82265e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e7b24-fb67-4074-bad0-6b466fb96830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4acd33b-9960-4c91-95d3-9c96dbf92b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf57031-7cd5-453d-96e7-26bcba211c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30412437-c338-4a3f-a553-abd9adf2ec7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d5d4a6-fe90-464e-bad1-9bd894b77aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be65602-168b-4d55-a9c5-631fed259b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0718b-d2f0-401c-b982-1fff02211611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f547320-2ea4-49bf-8d3a-c2cea428184f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad8e82-c8c6-4471-968e-7a659c01c684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d32ffac-3bc4-44f6-a2ea-647ac561f54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd65639-eae5-40a9-a0c4-8eabac6ecc10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa983a9-0c8f-4ee0-b5c8-4e2919276f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55db498-3ab8-4503-8693-fc47fdb537dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fbec79-11d5-4139-a51a-9f5aa4decdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3845140-f45b-4d24-9bda-b002f303d69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5dea6c-4fd8-46da-b1a1-6f62375a89b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d420a5-53fa-4f0e-92db-61069f3f919b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee36e8-456a-4964-8c5b-1f6ab0c9cceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c788b-f8ac-4d00-bd0d-b7bf2f6dcfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d583866-46e7-4747-b872-e913355aab86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ac20d-01ae-48bc-8559-03b5c44066a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c745add-0312-4014-9fcb-348372135538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c33b6-0ac4-4424-b467-b832ad1128d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83442ab6-76db-41f5-b2ca-90e099442a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a943cd-fe4c-4ba7-8024-f4a73359ca18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6f8dd-2203-4b86-8fe4-65472ef82601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c2d213-a837-4e2f-bb08-e8b8da1f89df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca9c71-28dd-4d66-a0b2-7b28d9c7ab86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9b252-cdeb-4ae7-ba68-56ae1efa7b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5a04d-df05-4018-94e7-e60c59d9ab26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65976db2-3fab-4860-82c2-e3636097ea61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ab68b-24ae-4134-8353-1d2e3f1131ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c7592-452c-4158-998f-4a88f6be5985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec222c-75ad-4d9c-b053-1d651b36ae73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112bdc3f-fbc3-48bf-9f31-4cd6765be54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069b09e-ec84-42a6-aa02-115a226727bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc65a17c-b985-4360-ba7f-cbd9d22a6825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92512599-e6dd-4655-88b4-4e42c92b7420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c87c6-3e88-4feb-baf7-a7144ef96932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e347b9d-edc8-411f-8dad-b62393260904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987a941-e5f1-464e-91a1-2a3469c3f2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d18695-5b4a-4d98-a2c6-049dc41f667e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79744e06-159e-4200-b733-de67f4b5ceb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9629c3-e938-4ca4-a79a-9effd679c022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcca58c-e3b1-430e-b3b5-f1d583452fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1148e40-9e50-49fd-9250-0259e90853f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525abd58-a980-48c8-923d-9b9209221570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc1403-a0e3-4585-97e3-69d08215419a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27f8ba-5aee-421f-9c47-0d312a2c282f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e275d-3167-461e-8115-e052694ffadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7c655-2560-4ae0-a5e8-0208838dc9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9849ff92-0740-4bfd-969b-6132473ada91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7beb1-2c81-49e8-a597-7e107353125c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4033cc-19e3-42f2-b14a-13b729012e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a9f24-aad4-413b-ae6c-24c7b0124c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0844f69-8ff7-4fa4-aa09-a427db3e1be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8bedb-6186-4cec-9377-b681544b4eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03914469-d76c-4a29-9f70-839f3aacf784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9840dc6-cce9-4b5a-a233-e4d3947906c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5818af-ed19-44f5-8373-c64c4efafd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa2d34c-2123-4868-9ad2-6e9cc6ebc5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf31f8-092d-48ed-9a33-f5a25373515c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0025891-955f-43f0-8cfc-e2830b53d16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc76d1-ee74-49ad-a569-a0d850630baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c7d769-da5b-4f83-bf5f-01ee181891b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e19027-a8b1-4fa8-9825-28025f77f6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf0a44-4b5a-4a41-92a6-675f40a13586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7b491c-d150-4191-b6ee-9182fe95c7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55d041-48d9-424b-8dc8-d9b17903d14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c90c32-6872-430b-b7b8-377dc5d64329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfabba5-826b-42de-bfa8-7ee958ced549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61865b03-f1f8-4025-a9f1-8f76485a887b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8254b7-c15b-4a77-86e3-d7cc9786ac1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd84e09-521c-4fd9-a147-01768e5e1110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2310f7d3-d7a3-4413-b4bf-2a947b12d3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235c55ee-f6da-49d3-8dde-9f0d53d1c710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e78b9-0a4b-4c0b-91cf-2c1a3be12f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b010e77-8bc0-416d-9e43-87e38d8f0da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e66a9d9-bba7-499b-9e4b-08ff6111dde4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ed7cd-b91c-4c25-9000-c3016e6a171b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62838efb-309b-4be6-a54e-f10bd234531d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3738e0-1772-42e3-ac9d-f82b633fd113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ddaf15-3eaa-4c13-87ef-451ca53acbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591152f6-3614-41cb-a379-6e7754ec9bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1f497-f157-4a1d-b7ea-c26f7953b89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf73f5b-48eb-42c5-9d69-492450e8cb69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107dd35-2cd1-4c5e-883c-c566bd089b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd80c2-6057-4b6d-a326-7759069bff0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e23ce45-e66b-45ac-803d-01f4f0969645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ba4b5-8781-44f4-832d-39184ad89ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ef4bf-3f11-430a-9699-d1117718e4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f9ebd-fd96-4a49-ac99-0c89918800b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e7012-ddb1-4bbd-b663-802dfad51a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04e940-c305-443e-a45f-4f6925ac5554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24135b28-bc43-4625-a1d7-dc75913cfd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8c3f1-38b9-417a-ae23-d4100d1f421f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717152f7-b6aa-42bf-adfa-c638736c0b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb514a3-fa1f-42e4-bb62-cb327bb7dab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a8e0b-9876-47b4-a38b-d0ad620f9f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a416ac47-7466-413b-a55c-89c4c7020f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94142a05-067c-4bb7-a281-7898fb50ffd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a0a73-9a2d-4760-825b-fda8f8e2ec6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003283f4-f8a2-497e-94fb-af8725a8d8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf06bb-7713-4a2b-8acd-f6a6991cb5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efe43b-73f1-42d9-a2fc-2daa6e11e234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8447885-c34c-4d05-99d4-d81511ecebb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd9d02-640c-401d-803d-25b1de00e6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553fc05a-9a18-41e5-bcb0-c70d5da04cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758f313-b6b7-4b15-94c6-b69b0718f1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3fdb1-1cc2-49a2-a882-3af10c743e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a56852-bc18-41d7-8166-68abf3ca3b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ddf450-d3bd-4b9a-9b71-124da6423910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378f510-13f3-45fc-8f46-9d926fa2d55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6c13e-46d6-41b1-b696-01cff4918956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea820d9-2212-405a-9ba7-d760c047aee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9652f4-1358-4f96-a55d-1753da371798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844bb3d-024d-46fb-ac5d-00852622a19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6587c-beb5-4de5-aad6-150434b432e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d06b62-53f9-4246-80ab-427fbeac8103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f95dbc-af64-404e-b608-17e0e21f97a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d226e-f7e2-496a-be1d-b6ae87ec4584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018526c0-ae2a-4dfd-824d-31508d207fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00efa941-b48a-4d10-b78a-12e767e34872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43620d11-ba69-4acb-bb21-1bf490f230d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17538d49-1248-4d96-870a-34d0e27b4b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d36b50-c83d-4692-b198-e6e29c2ec081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10ed7b-3ff3-4175-8105-12d16947dd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7bdfa8-337e-4b2a-9873-58724935d839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae369d7-6764-4fe0-a79d-e642c523af43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9900a-0853-4f45-b826-0410312f54b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e710a21-dd54-45cc-8371-f1c09ba5ce96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f264e-9047-4148-8126-5573b8554b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc86af-35dd-4a10-a732-88cee0410ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec813d8-35de-4638-bb3d-08d3f2f2f763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5619de4-8c04-46c4-883a-8f03d0dfce12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9fbba-8e9e-47aa-9f6c-b19939878b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ecd552-1654-4682-8131-b258d1ed152b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f040e3-ad77-4e15-acab-f09f14558efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351b82d-b821-4e0a-bff7-87f20e1508d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e304623-a76d-40b2-bea8-0b9a1a133b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4ea5e-d5dc-4e38-8be8-07b0c86ffae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce88b0c-6ba1-424a-aa96-6dd525551ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e97751-b19e-46f1-a8f2-b8f6d662a1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bbf809-261d-43f5-b25d-1efbe1a517b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a9415-354f-47d0-89c8-54e49de3a107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a4fed-41f7-460f-80d0-7e4d90b80fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70594cbe-2fcf-48b7-b7ef-1aeeee54f91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f585edbc-5cf0-4a05-a94f-b79da5e60a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11386ba5-cb7c-48eb-88f2-0172ad6f3a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc928934-e3c2-4f7b-937f-6dda13a0b629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db09aa-ebde-4e45-934c-59a15100809b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34bf155-6090-4b28-9487-00ee3c52d4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c07ecab-e23d-423f-af0b-b6e106277885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d9d68-e542-4924-b68b-cc58b68bf273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da36e16-b848-45de-aef9-a53ed7ad0242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da272d23-c83c-4b8f-a2ce-89028f159baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58413c-e6e0-46d4-8efd-0680a2bdec75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18489132-09b7-400f-a675-2159744bd3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54009efb-f2c5-45b3-93d3-4ef90dd047ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd74170-4f81-4f5f-8893-525441b6dd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d47385-07ec-4014-890e-34bebf712774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f199b-49a5-464e-a1ff-f23382c746e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf82293-99de-4943-b847-fe51fff7fd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dfd2ba-9501-41e1-bb6e-0bbff7f9b459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59496727-a164-41f8-9ebd-17cfba1e44fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e5ffe-697d-46d7-b9fe-2be4965560ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43365ad-f594-43b2-9c24-1d8433910f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e317e73-7375-4ffb-859c-a7916d235145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d29925-bfd2-4fea-a184-264b6af142cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa690a5-417a-433f-8475-d5ad3d663432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea419c-8062-4405-8dd7-ea35f25fda0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a71ab-1929-41c6-95c9-e0e3e0c61807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d8da2-81c3-455f-9d73-f12458302e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43887974-3dd6-4e48-a394-a936df8c92c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b82a52-53c1-41b1-b35c-a8b21e209ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8feba7-eb29-4b48-88c2-358c0c17a53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4611134-2d4d-430d-b557-69c472c271be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12c6012-4b4f-413a-8e65-634da826f2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ed13e-bf31-4ff2-b2b0-b5ccbf174bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18e832-b00c-4ae3-a66e-c0c740ee7510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e537e3-c02a-4384-aed7-7a6eaf7eff93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93d940-d2c8-4ae7-9859-0cb10a4298a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13579e1-4f6a-4b8d-a6ce-54891e1450c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6731c671-caef-40c2-b84d-95d3f5e740f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258561b-6425-4472-91d8-584cb1d4c50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768d3b9-f670-41af-8217-6341565a4a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ab6ca-b853-4ea0-b089-160adeee28ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744abc9-8364-44ba-9911-86625e1c9dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379e3ff-4066-4eca-843e-9ca129c52d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee284590-4054-4652-9adb-9c863d831275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b9ef6-4255-47a9-ab04-77da63e0ee87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed798c3-74a5-42d0-8804-c9146b426ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5265169-50ea-4df0-a491-0112b09fa6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf47f4f-6d83-4281-bb08-0224f17c898a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424a3b4-7a0a-448a-af0d-ad8183619cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341aaa3-7a1c-4ae5-b043-14152f4e47fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864ba86-cd66-47db-8b38-5404f1019037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b55951-8968-4096-9b50-67e3a6b68097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec0000-e00e-4826-b89d-4e9108975507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd7fe6-d26b-4d06-a253-6f243cfb7a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c764936-d252-4348-b638-547ee8bd3ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666f16b-dfa7-421a-a082-fe7fb378f53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d366e-9af1-44d7-a3bc-5a7b9bedf8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00122c24-3be8-49b7-b000-f76eb05128bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0861d-1331-4738-8272-43b7ac27ffa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad942c18-21d7-4a9d-8f3b-a79546b4e55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4ae3b-8419-4e95-aeb0-49a00dcea86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b33cef-8bc3-4a41-8b8c-3fded9a837a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b08cd-26e2-4f16-81c9-069bdee24387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373da5c5-dd68-4cf2-8be9-babb1589a885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5daf9f8-0bda-4076-bda1-8e4e26e269cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee1fd3-18de-4b53-a9b9-9c51b4a902f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398b6f8-1565-40f1-937f-f3d89f9f0ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6848e-b942-406d-abd0-8eb50b9f7a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86edd1-20c9-454b-af17-ab0315369108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6312bdaa-94ed-4443-9143-e0d870e182ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf28d411-b783-4aa4-accf-5a047aa18f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791dceb-5aa9-4180-892c-abec85c0ea6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e133ada2-3bcc-44ba-9f9f-df96b810ecbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc16737-38d7-483c-aa43-7e1efc76aeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e59981-9aa0-4ebf-8115-eb062efcc355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d912c-1121-4cbe-8162-3040e540dce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d78404-d206-4cae-b87f-5ed86a0c1ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b622398-f2a6-4e4c-8174-9f68d9153724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94827c9e-674f-40ac-af44-0ae6cc063e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76613f-fe3c-445e-8ad8-e1bf4f875b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5dc83-e35d-4e3a-894a-7b19a85b5b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02594a18-047e-442f-86ff-46ce8f1f18b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be95b3dc-7b58-4fb9-a5a9-1f22cf42b819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad0d4f9-4f99-4e86-82e9-3c7cbe5f574a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c1d07-bdfb-49ce-a3c6-b3b7969d1543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c0523-7d25-4889-9a76-19b5a81d81f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4752a9d-f234-4f05-af95-86dcdbe2fdaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd4002-81e2-4803-a799-2d0e384ee8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1256e20-dfad-4dc9-9b5a-57f9a7eec4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8dad8-6ee1-4bc7-976f-fbda79a6d0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8fc06-7eb9-4f7e-9985-d1781a1646d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
